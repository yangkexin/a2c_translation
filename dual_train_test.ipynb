{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(alpha=0.01, cuda=True, dict=['data/dict.an.pkl', 'data/dict.ch.pkl'], lm=['data/a2c_an.pt', 'data/a2c_ch.pt'], log_every=500, lr=1e-05, model=['trained_model/model_an-ch_adam', 'trained_model/model_ch-an_adam'], nmt=['data/model.an_ch.bin', 'data/model.ch_an.bin'], save_n_iter=2000, src=['data/an_new.txt', 'data/ch_new.txt'], start_iter=0)\n",
      "loading pieces, part A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  load modelA     from [data/model.an_ch.bin]\n",
      "  load train_srcA from [data/an_new.txt]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  load lmA        from [data/a2c_an.pt]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pieces, part B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  load modelB     from [data/model.ch_an.bin]\n",
      "  load train_srcB from [data/ch_new.txt]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  load lmB        from [data/a2c_ch.pt]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start of epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/pytorch-dual-learning-master/nmt/model.py:531: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  att_weight = F.softmax(att_weight)\n",
      "/home/workspace/pytorch-dual-learning-master/nmt/model.py:405: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p_t = F.log_softmax(score_t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "step 500\n",
      "\n",
      "A -> B\n",
      "[s] 不 过 三 旬 ，\n",
      "[smid] <s> 不 过 三 十 天 ， </s>\n",
      "[smid] <s> 不 超 过 三 十 天 ， </s>\n",
      "[smid] <s> 不 经 过 三 十 天 ， </s>\n",
      "[smid] <s> 不 过 三 十 天 十 天 ， </s>\n",
      "[smid] <s> 不 过 三 十 天 过 了 ， </s>\n",
      "r1= 0.9174\t r2= 0.2468\t rk= 0.2535\t fw_loss= 0.3782\t bw_loss= 0.5240\n",
      "r1= 0.3795\t r2= 1.2841\t rk= 1.2751\t fw_loss= 0.4138\t bw_loss= 0.3749\n",
      "r1= 0.7979\t r2= 0.4907\t rk= 0.4937\t fw_loss= 0.5901\t bw_loss= 0.4889\n",
      "r1=-1.3503\t r2=-0.9558\t rk=-0.9598\t fw_loss= 0.6400\t bw_loss= 0.6969\n",
      "r1=-0.7445\t r2=-1.0657\t rk=-1.0625\t fw_loss= 0.7124\t bw_loss= 0.7127\n",
      "A loss = -0.0912665 \t B loss = 0.5539014\n",
      "\n",
      "B -> A\n",
      "[s] 克 扣 我 们 的 俸 给 和 借 贷 ？\n",
      "[smid] <s> 不 与 贷 贷 ？ </s>\n",
      "[smid] <s> 不 与 假 与 贷 ？ </s>\n",
      "[smid] <s> 克 之 与 假 与 贷 ？ </s>\n",
      "[smid] <s> 克 之 与 假 与 贷 ！ </s>\n",
      "[smid] <s> 不 与 假 与 假 与 ？ </s>\n",
      "r1= 1.0460\t r2=-0.3048\t rk=-0.2913\t fw_loss= 1.4128\t bw_loss= 4.9816\n",
      "r1= 0.6474\t r2= 0.2389\t rk= 0.2429\t fw_loss= 1.3028\t bw_loss= 4.8538\n",
      "r1=-1.0372\t r2= 1.3587\t rk= 1.3348\t fw_loss= 1.2899\t bw_loss= 4.5906\n",
      "r1=-1.1013\t r2= 0.1179\t rk= 0.1057\t fw_loss= 1.3083\t bw_loss= 4.8822\n",
      "r1= 0.4451\t r2=-1.4107\t rk=-1.3921\t fw_loss= 1.3163\t bw_loss= 5.2415\n",
      "A loss = -0.0134944 \t B loss = 4.8608518\n",
      "====================\n",
      "live_hyp_num: 5\n",
      "====================\n",
      "top_new_hyp_pos: Variable containing:\n",
      " 9.2234e+18\n",
      " 9.2234e+18\n",
      " 9.2234e+18\n",
      " 9.2234e+18\n",
      " 9.2234e+18\n",
      "[torch.cuda.LongTensor of size 5 (GPU 0)]\n",
      "\n",
      "====================\n",
      "tgt_vocab_size: 5132\n",
      "====================\n",
      "prev_hyp_ids: Variable containing:\n",
      " 1.7972e+15\n",
      " 1.7972e+15\n",
      " 1.7972e+15\n",
      " 1.7972e+15\n",
      " 1.7972e+15\n",
      "[torch.cuda.LongTensor of size 5 (GPU 0)]\n",
      "\n",
      "====================\n",
      "len(p_t_cpu): 1\n",
      "====================\n",
      "src_sents: [['隋', '炀', '帝', '到', '江', '都', '，']]\n",
      "====================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "seq can't be empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/home/workspace/pytorch-dual-learning-master/dual.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0mdual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/workspace/pytorch-dual-learning-master/dual.py\u001b[0m in \u001b[0;36mdual\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[s]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mhyps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhyps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/workspace/pytorch-dual-learning-master/nmt/model.py\u001b[0m in \u001b[0;36mbeam\u001b[0;34m(self, src_sents, beam_size)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# merge variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdists\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompleted_out_dists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             \u001b[0mcompleted_out_dists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# sort with scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: seq can't be empty"
     ]
    }
   ],
   "source": [
    "%run dual.py --nmt data/model.an_ch.bin data/model.ch_an.bin \\\n",
    "    --lm data/a2c_an.pt data/a2c_ch.pt \\\n",
    "    --dict data/dict.an.pkl data/dict.ch.pkl \\\n",
    "    --src data/an_new.txt data/ch_new.txt \\\n",
    "    --log_every 500 \\\n",
    "    --save_n_iter 2000 \\\n",
    "    --alpha 0.01 \\\n",
    "    --model \"trained_model/model_an-ch_adam\" \"trained_model/model_ch-an_adam\" \\\n",
    "    --lr 1e-5 \\\n",
    "    --cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试NMT中的an_ch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beam_size=5, clip_grad=5.0, cuda=True, debug=False, decode_max_time_step=200, dev_src=None, dev_tgt=None, dropout=0.0, embed_size=256, hidden_size=256, load_model='data/model.an_ch.bin', log_every=50, lr=0.001, lr_decay=0.5, max_niter=-1, mode='test', patience=5, raml_bias_groundtruth=False, raml_sample_file=None, raml_sample_mode='pre_sample', sample_method='random', sample_size=10, save_model_after=2, save_nbest=False, save_to='model', save_to_file='my_test_result/nmt_an_ch_result.txt', seed=5783287, smooth_bleu=False, temp=0.85, test_src='data/an_test.txt', test_tgt='data/ch_test.txt', train_src=None, train_tgt=None, uniform_init=None, valid_metric='bleu', valid_niter=500, vocab=None)\n",
      "load model from [data/model.an_ch.bin]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success read\n",
      "success read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/pytorch-dual-learning-master/nmt/nmt.py:453: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  att_weight = F.softmax(att_weight)\n",
      "/home/workspace/pytorch-dual-learning-master/nmt/nmt.py:278: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p_t = F.log_softmax(score_t)\n",
      "decoded 2000 examples, took 40 s\n",
      "save decoding results to my_test_result/nmt_an_ch_result.txt\n"
     ]
    }
   ],
   "source": [
    "%run nmt/nmt.py --cuda --mode test --test_src \"data/an_test.txt\" --test_tgt \"data/ch_test.txt\" --load_model \"data/model.an_ch.bin\" --save_to_file \"my_test_result/nmt_an_ch_result.txt\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试NMT中的ch_an model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beam_size=5, clip_grad=5.0, cuda=True, debug=False, decode_max_time_step=200, dev_src=None, dev_tgt=None, dropout=0.0, embed_size=256, hidden_size=256, load_model='data/model.ch_an.bin', log_every=50, lr=0.001, lr_decay=0.5, max_niter=-1, mode='test', patience=5, raml_bias_groundtruth=False, raml_sample_file=None, raml_sample_mode='pre_sample', sample_method='random', sample_size=10, save_model_after=2, save_nbest=False, save_to='model', save_to_file='my_test_result/nmt_ch_an_result.txt', seed=5783287, smooth_bleu=False, temp=0.85, test_src='data/ch_test.txt', test_tgt='data/an_test.txt', train_src=None, train_tgt=None, uniform_init=None, valid_metric='bleu', valid_niter=500, vocab=None)\n",
      "load model from [data/model.ch_an.bin]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success read\n",
      "success read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/pytorch-dual-learning-master/nmt/nmt.py:453: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  att_weight = F.softmax(att_weight)\n",
      "/home/workspace/pytorch-dual-learning-master/nmt/nmt.py:278: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p_t = F.log_softmax(score_t)\n",
      "decoded 2000 examples, took 31 s\n",
      "save decoding results to my_test_result/nmt_ch_an_result.txt\n"
     ]
    }
   ],
   "source": [
    "%run nmt/nmt.py --cuda --mode test --test_src \"data/ch_test.txt\" --test_tgt \"data/an_test.txt\" --load_model \"data/model.ch_an.bin\" --save_to_file \"my_test_result/nmt_ch_an_result.txt\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试dual_NMT中的an_ch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beam_size=5, clip_grad=5.0, cuda=True, debug=False, decode_max_time_step=200, dev_src=None, dev_tgt=None, dropout=0.0, embed_size=256, hidden_size=256, load_model='trained_model/model_an-ch.iter4000.bin', log_every=50, lr=0.001, lr_decay=0.5, max_niter=-1, mode='test', patience=5, raml_bias_groundtruth=False, raml_sample_file=None, raml_sample_mode='pre_sample', sample_method='random', sample_size=10, save_model_after=2, save_nbest=False, save_to='model', save_to_file='my_test_result/dual_an_ch_result.txt', seed=5783287, smooth_bleu=False, temp=0.85, test_src='data/an_test.txt', test_tgt='data/ch_test.txt', train_src=None, train_tgt=None, uniform_init=None, valid_metric='bleu', valid_niter=500, vocab=None)\n",
      "load model from [trained_model/model_an-ch.iter4000.bin]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success read\n",
      "success read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/pytorch-dual-learning-master/nmt/nmt.py:453: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  att_weight = F.softmax(att_weight)\n",
      "/home/workspace/pytorch-dual-learning-master/nmt/nmt.py:278: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p_t = F.log_softmax(score_t)\n",
      "decoded 2000 examples, took 37 s\n",
      "save decoding results to my_test_result/dual_an_ch_result.txt\n"
     ]
    }
   ],
   "source": [
    "%run nmt/nmt.py --cuda --mode test --test_src \"data/an_test.txt\" --test_tgt \"data/ch_test.txt\" --load_model \"trained_model/model_an-ch.iter4000.bin\" --save_to_file \"my_test_result/dual_an_ch_result.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试dual_NMT中的ch_an model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beam_size=5, clip_grad=5.0, cuda=True, debug=False, decode_max_time_step=200, dev_src=None, dev_tgt=None, dropout=0.0, embed_size=256, hidden_size=256, load_model='trained_model/model_ch-an.iter4000.bin', log_every=50, lr=0.001, lr_decay=0.5, max_niter=-1, mode='test', patience=5, raml_bias_groundtruth=False, raml_sample_file=None, raml_sample_mode='pre_sample', sample_method='random', sample_size=10, save_model_after=2, save_nbest=False, save_to='model', save_to_file='my_test_result/dual_ch_an_result.txt', seed=5783287, smooth_bleu=False, temp=0.85, test_src='data/ch_test.txt', test_tgt='data/an_test.txt', train_src=None, train_tgt=None, uniform_init=None, valid_metric='bleu', valid_niter=500, vocab=None)\n",
      "load model from [trained_model/model_ch-an.iter4000.bin]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success read\n",
      "success read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/pytorch-dual-learning-master/nmt/nmt.py:453: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  att_weight = F.softmax(att_weight)\n",
      "/home/workspace/pytorch-dual-learning-master/nmt/nmt.py:278: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p_t = F.log_softmax(score_t)\n",
      "decoded 2000 examples, took 25 s\n",
      "save decoding results to my_test_result/dual_ch_an_result.txt\n"
     ]
    }
   ],
   "source": [
    "%run nmt/nmt.py --cuda --mode test --test_src \"data/ch_test.txt\" --test_tgt \"data/an_test.txt\" --load_model \"trained_model/model_ch-an.iter4000.bin\" --save_to_file \"my_test_result/dual_ch_an_result.txt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
